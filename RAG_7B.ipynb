{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8cGRexz2ORw",
        "outputId": "a61b70b2-2e11-47d8-cf92-7e35505fffe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q \"langchain\" \"transformers==4.31.0\" \"datasets==2.13.0\" \"peft==0.4.0\" \"accelerate==0.21.0\" \"bitsandbytes==0.40.2\" \"trl==0.4.7\" \"safetensors>=0.3.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCS1F6412XZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267bdb0f-0a70-472e-a4b4-c0b0468a78cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U faiss-cpu tiktoken sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73DmEV3I9Chj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f3acf2-8a62-4cd0-b2dd-be45514e5f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ctransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.20.2)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2023.11.17)\n",
            "Installing collected packages: ctransformers\n",
            "Successfully installed ctransformers-0.2.27\n"
          ]
        }
      ],
      "source": [
        "!pip install ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiFEzbyg0DJV"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import CTransformers\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.embeddings import GPT4AllEmbeddings\n",
        "from langchain_community.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP681Rpe1Evd"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain_community.document_loaders import TextLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "c0MAu3mI3MMj"
      },
      "outputs": [],
      "source": [
        "documents = TextLoader('/content/BDS.txt').load()\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size = 400, # the character length of the chunk\n",
        "    chunk_overlap = 30, # the character length of the overlap between chunks\n",
        "    length_function = len, # the length function - in this case, character length (aka the python len() fn.)\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usY1z5qu1jab"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import CacheBackedEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "core_embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=embed_model_id\n",
        ")\n",
        "\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings_model, store, namespace=embed_model_id\n",
        ")\n",
        "\n",
        "db = FAISS.from_documents(chunks,embedder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEIHVBUL0600"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Khai bao bien\n",
        "# pdf_data_path = \"data\"\n",
        "# vector_db_path = \"vectorstores/db_faiss\"\n",
        "\n",
        "# # Ham 1. Tao ra vector DB tu 1 doan text\n",
        "# raw_text = \"\"\"Cho thuê căn hộ dịch vụ Mai Động, Phường Mai Động, Quận Hoàng Mai, giá 4tr, diện tích 70m2. Thông tin phòng GIÁ PHÒNG 4,000,000 đồng. ĐẶT CỌC 4,000,000 đồng. ĐIỆN Miễn phí NƯỚC Miễn phí, WIFI Miễn phí. TRẠNG THÁI Còn phòng. ĐIẠ CHỈ 104C39 tập thể mai động Mai động, Phường Mai Động, Quận Hoàng Mai, Hà Nội. Tiện ích Máy lạnh WC riêng Chổ để xe Wifi Tự do Không chung chủ . Bảo vệ Nấu ăn Máy nước nóng. Lưu ý Tiện ích Không cửa sổ. Sức chứa Rộng 6. Mô tả thêm Điện nước tự thanh toán qua momo giá nhà nước! Mùa hè nhà siêu mát, rộng rãi, thoải mái sửa chữa và decor\n",
        "# \"\"\"\n",
        "#     # Chia nho van ban\n",
        "# text_splitter = CharacterTextSplitter(\n",
        "# separator=\"\\n\",\n",
        "# chunk_size=512,\n",
        "# chunk_overlap=50,\n",
        "# length_function=len\n",
        "\n",
        "# )\n",
        "\n",
        "# chunks = text_splitter.split_text(raw_text)\n",
        "\n",
        "#     # Embeding\n",
        "# embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "# embeddings_model = HuggingFaceEmbeddings(model_name=embed_model_id)\n",
        "\n",
        "#     # Dua vao Faiss Vector DB\n",
        "# db = FAISS.from_texts(texts=chunks, embeddings_model)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file=\"/content/vinallama-7b-chat-GGUF\""
      ],
      "metadata": {
        "id": "lznYoSMNMhz7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "HQ7jLJ3nTimY"
      },
      "outputs": [],
      "source": [
        "def load_llm(model_file):\n",
        "    llm = CTransformers(\n",
        "        model=model_file,\n",
        "        model_type=\"llama\",\n",
        "        max_new_tokens=1024,\n",
        "        temperature=0.01\n",
        "    )\n",
        "    return llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "RS7WCnW1aD9m"
      },
      "outputs": [],
      "source": [
        "# Tao prompt template\n",
        "def creat_prompt(template):\n",
        "    prompt = PromptTemplate(template = template, input_variables=[\"context\", \"question\"])\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JifsQV7YaPiX"
      },
      "outputs": [],
      "source": [
        "def create_qa_chain(prompt, llm, db):\n",
        "    llm_chain = RetrievalQA.from_chain_type(\n",
        "        llm = llm,\n",
        "        chain_type= \"stuff\",\n",
        "        retriever = db.as_retriever(search_kwargs = {\"k\":3}, max_tokens_limit=1024),\n",
        "        return_source_documents = False,\n",
        "        chain_type_kwargs= {'prompt': prompt}\n",
        "\n",
        "    )\n",
        "    return llm_chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUJaw1rOzfLd"
      },
      "outputs": [],
      "source": [
        "# # Read tu VectorDB\n",
        "# def read_vectors_db():\n",
        "#     # Embeding\n",
        "#     embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "#     embeddings_model = HuggingFaceEmbeddings(\n",
        "#     model_name=embed_model_id\n",
        "#       )\n",
        "#     db = FAISS.load_local(vector_db_path, embedding_model)\n",
        "#     return db\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "AYPWA4WQwD3f"
      },
      "outputs": [],
      "source": [
        "# Tao prompt template\n",
        "def creat_prompt(template):\n",
        "    prompt = PromptTemplate(template = template, input_variables=[\"context\", \"question\"])\n",
        "    return prompt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCXUzPMpAPAR"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface-hub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "mulll3eKAWbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da0616a-657f-41b9-b375-836a76890764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.system(\"sudo apt install git\")\n",
        "!sudo apt install git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-eHHUGYwfhN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Bat dau thu nghiem\n",
        "#db = read_vectors_db()\n",
        "llm = load_llm(model_file)\n",
        "\n",
        "#Tao Prompt\n",
        "template = \"\"\"<|im_start|>system\\nSử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời\\n\n",
        "    {context}<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\"\"\"\n",
        "prompt = creat_prompt(template)\n",
        "\n",
        "llm_chain  =create_qa_chain(prompt, llm, db)\n",
        "\n",
        "# Chay cai chain\n",
        "question = \"Điện nước thanh toán thế nào?\"\n",
        "response = llm_chain.invoke({\"query\": question})\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
